# Reasoning Abilities of LLMs
*Here're some resources about understanding and leveraging Reasoning Abilities of LLMs*




### General

#### Chameleon: Plug-and-play compositional reasoning with large language models

paper link: [here](https://arxiv.org/pdf/2304.09842)

citation: 
```bibtex
@article{lu2023chameleon,
  title={Chameleon: Plug-and-play compositional reasoning with large language models},
  author={Lu, Pan and Peng, Baolin and Cheng, Hao and Galley, Michel and Chang, Kai-Wei and Wu, Ying Nian and Zhu, Song-Chun and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2304.09842},
  year={2023}
}
```


#### Why think step-by-step? Reasoning emerges from the locality of experience

paper link: [here](https://arxiv.org/pdf/2304.03843)

citation: 
```bibtex
@article{prystawski2023think,
  title={Why think step-by-step? Reasoning emerges from the locality of experience},
  author={Prystawski, Ben and Goodman, Noah D},
  journal={arXiv preprint arXiv:2304.03843},
  year={2023}
}
```

#### Pal: Program-aided language models

paper link: [here](https://proceedings.mlr.press/v202/gao23f/gao23f.pdf)

citation: 
```bibtex
@inproceedings{gao2023pal,
  title={Pal: Program-aided language models},
  author={Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  booktitle={International Conference on Machine Learning},
  pages={10764--10799},
  year={2023},
  organization={PMLR}
}
```

#### Visual programming: Compositional visual reasoning without training

paper link: [here](https://openaccess.thecvf.com/content/CVPR2023/papers/Gupta_Visual_Programming_Compositional_Visual_Reasoning_Without_Training_CVPR_2023_paper.pdf)

citation: 
```bibtex
@inproceedings{gupta2023visual,
  title={Visual programming: Compositional visual reasoning without training},
  author={Gupta, Tanmay and Kembhavi, Aniruddha},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14953--14962},
  year={2023}
}
```


#### Large language models can self-improve

paper link: [here](https://arxiv.org/pdf/2210.11610.pdf)

citation: 
```bibtex
@article{huang2022large,
  title={Large language models can self-improve},
  author={Huang, Jiaxin and Gu, Shixiang Shane and Hou, Le and Wu, Yuexin and Wang, Xuezhi and Yu, Hongkun and Han, Jiawei},
  journal={arXiv preprint arXiv:2210.11610},
  year={2022}
}
```

#### React: Synergizing reasoning and acting in language models

paper link: [here](https://arxiv.org/pdf/2210.03629.pdf)

citation: 
```bibtex
@article{yao2022react,
  title={React: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal={arXiv preprint arXiv:2210.03629},
  year={2022}
}
```



#### Language models show human-like content effects on reasoning

paper link: [here](https://arxiv.org/pdf/2207.07051.pdf)

citation: 
```bibtex
@article{dasgupta2022language,
  title={Language models show human-like content effects on reasoning},
  author={Dasgupta, Ishita and Lampinen, Andrew K and Chan, Stephanie CY and Creswell, Antonia and Kumaran, Dharshan and McClelland, James L and Hill, Felix},
  journal={arXiv preprint arXiv:2207.07051},
  year={2022}
}
```


#### Self-consistency improves chain of thought reasoning in language models

paper link: [here](https://arxiv.org/pdf/2203.11171.pdf)

citation: 
```bibtex
@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}
```


### Decision Making / Planning


#### Towards end-to-end embodied decision making via multi-modal large language model: Explorations with gpt4-vision and beyond

paper link: [here](https://arxiv.org/pdf/2310.02071)

citation: 
```bibtex
@article{chen2023towards,
  title={Towards end-to-end embodied decision making via multi-modal large language model: Explorations with gpt4-vision and beyond},
  author={Chen, Liang and Zhang, Yichi and Ren, Shuhuai and Zhao, Haozhe and Cai, Zefan and Wang, Yuchi and Wang, Peiyi and Liu, Tianyu and Chang, Baobao},
  journal={arXiv preprint arXiv:2310.02071},
  year={2023}
}
```
    

#### ChessGPT: Bridging Policy Learning and Language Modeling

paper link: [here](https://arxiv.org/pdf/2306.09200)

citation: 
```bibtex
@article{feng2023chessgpt,
  title={ChessGPT: Bridging Policy Learning and Language Modeling},
  author={Feng, Xidong and Luo, Yicheng and Wang, Ziyan and Tang, Hongrui and Yang, Mengyue and Shao, Kun and Mguni, David and Du, Yali and Wang, Jun},
  journal={arXiv preprint arXiv:2306.09200},
  year={2023}
}
```

#### Language models can solve computer tasks

paper link: [here](https://arxiv.org/pdf/2303.17491)

citation: 
```bibtex
@article{kim2023language,
  title={Language models can solve computer tasks},
  author={Kim, Geunwoo and Baldi, Pierre and McAleer, Stephen},
  journal={arXiv preprint arXiv:2303.17491},
  year={2023}
}
```

#### Progprompt: Generating situated robot task plans using large language models

paper link: [here](https://arxiv.org/pdf/2209.11302)

citation: 
```bibtex
@inproceedings{singh2023progprompt,
  title={Progprompt: Generating situated robot task plans using large language models},
  author={Singh, Ishika and Blukis, Valts and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Thomason, Jesse and Garg, Animesh},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={11523--11530},
  year={2023},
  organization={IEEE}
}
```

#### Language models as zero-shot planners: Extracting actionable knowledge for embodied agents

paper link: [here](https://proceedings.mlr.press/v162/huang22a/huang22a.pdf)

citation: 
```bibtex
@inproceedings{huang2022language,
  title={Language models as zero-shot planners: Extracting actionable knowledge for embodied agents},
  author={Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  booktitle={International Conference on Machine Learning},
  pages={9118--9147},
  year={2022},
  organization={PMLR}
}
```


### Math-Solving Problems

#### Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B

paper link: [here](https://arxiv.org/pdf/2406.07394)

citation:

```bibtex
@misc{zhang2024accessinggpt4levelmathematical,
      title={Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B}, 
      author={Di Zhang and Xiaoshui Huang and Dongzhan Zhou and Yuqiang Li and Wanli Ouyang},
      year={2024},
      eprint={2406.07394},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
      url={https://arxiv.org/abs/2406.07394}, 
}
```

#### AlphaMath Almost Zero: process Supervision without process

paper link: [here](https://arxiv.org/pdf/2405.03553)

citation:

```bibtex
@misc{chen2024alphamathzeroprocesssupervision,
      title={AlphaMath Almost Zero: process Supervision without process}, 
      author={Guoxin Chen and Minpeng Liao and Chengxi Li and Kai Fan},
      year={2024},
      eprint={2405.03553},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
      url={https://arxiv.org/abs/2405.03553}, 
}
```


#### Forward-Backward Reasoning in Large Language Models for Mathematical Verification

paper link: [here](https://arxiv.org/pdf/2308.07758)

citation:

```bibtex
@misc{jiang2024forwardbackward,
      title={Forward-Backward Reasoning in Large Language Models for Mathematical Verification}, 
      author={Weisen Jiang and Han Shi and Longhui Yu and Zhengying Liu and Yu Zhang and Zhenguo Li and James T. Kwok},
      year={2024},
      eprint={2308.07758},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

#### Scaling Relationship on Learning Mathematical Reasoning with Large Language Models (RFT)

paper link: [here](https://arxiv.org/pdf/2308.01825)

github link: [here](https://github.com/OFA-Sys/gsm8k-ScRel)

citation:

```bibtex
@misc{yuan2023scaling,
      title={Scaling Relationship on Learning Mathematical Reasoning with Large Language Models}, 
      author={Zheng Yuan and Hongyi Yuan and Chengpeng Li and Guanting Dong and Keming Lu and Chuanqi Tan and Chang Zhou and Jingren Zhou},
      year={2023},
      eprint={2308.01825},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```


#### Don't Trust- Verify - Grounding LLM Quantitative Reasoning With AutoFormalization

paper link: [here](https://openreview.net/pdf?id=V5tdi14ple)

citation:

```bibtex
@inproceedings{zhou2024dont,
  title={Don't Trust: Verify -- Grounding {LLM} Quantitative Reasoning with Autoformalization},
  author={Jin Peng Zhou and Charles E Staats and Wenda Li and Christian Szegedy and Kilian Q Weinberger and Yuhuai Wu},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024},
  url={https://openreview.net/forum?id=V5tdi14ple}
}
```


#### LeanDojo: Theorem Proving with Retrieval-Augmented Language Models

paper link: [here](https://arxiv.org/pdf/2306.15626.pdf)

github link: [here](https://github.com/lean-dojo/LeanDojo)

citation:

```bibtex
@inproceedings{yang2023leandojo,
  title={{LeanDojo}: Theorem Proving with Retrieval-Augmented Language Models},
  author={Yang, Kaiyu and Swope, Aidan and Gu, Alex and Chalamala, Rahul and Song, Peiyang and Yu, Shixing and Godil, Saad and Prenger, Ryan and Anandkumar, Anima},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  year={2023}
}
```


#### An Empirical Study on Challenging Math Problem Solving with GPT-4

paper link: [here](https://arxiv.org/pdf/2306.01337.pdf)

citation:

```bibtex
@misc{wu2023empirical,
      title={An Empirical Study on Challenging Math Problem Solving with GPT-4}, 
      author={Yiran Wu and Feiran Jia and Shaokun Zhang and Hangyu Li and Erkang Zhu and Yue Wang and Yin Tat Lee and Richard Peng and Qingyun Wu and Chi Wang},
      year={2023},
      eprint={2306.01337},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

#### Can Language Models Solve Graph Problems in Natural Language?

paper link: [here](https://arxiv.org/pdf/2305.10037)

citation: 
```bibtex
@article{wang2023can,
  title={Can Language Models Solve Graph Problems in Natural Language?},
  author={Wang, Heng and Feng, Shangbin and He, Tianxing and Tan, Zhaoxuan and Han, Xiaochuang and Tsvetkov, Yulia},
  journal={arXiv preprint arXiv:2305.10037},
  year={2023}
}
```
    


#### ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving

paper link: [here](https://arxiv.org/pdf/2309.17452)

citation: 
```bibtex
@article{gou2023tora,
  title={ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving},
  author={Gou, Zhibin and Shao, Zhihong and Gong, Yeyun and Yang, Yujiu and Huang, Minlie and Duan, Nan and Chen, Weizhu and others},
  journal={arXiv preprint arXiv:2309.17452},
  year={2023}
}
```    


#### Multi-View Reasoning: Consistent Contrastive Learning for Math Word Problem

paper link: [here](https://arxiv.org/pdf/2210.11694)

citation: 
```bibtex
@article{zhang2022multi,
  title={Multi-View Reasoning: Consistent Contrastive Learning for Math Word Problem},
  author={Zhang, Wenqi and Shen, Yongliang and Ma, Yanna and Cheng, Xiaoxia and Tan, Zeqi and Nong, Qingpeng and Lu, Weiming},
  journal={arXiv preprint arXiv:2210.11694},
  year={2022}
}
```



    


    


    