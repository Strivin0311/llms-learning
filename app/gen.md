# LLMs for Generative Applications
*Here're some resources about LLMs for Generative Applications beyond chat*



### Procedural Content Generation (PCG)


#### MarioGPT: Open-Ended Text2Level Generation through Large Language Models [`UNREAD`]

paper link: [here](https://arxiv.org/abs/2302.05981)

citation: 
```bibtex
@misc{sudhakaran2023mariogpt,
      title={MarioGPT: Open-Ended Text2Level Generation through Large Language Models}, 
      author={Shyam Sudhakaran and Miguel Gonz√°lez-Duque and Claire Glanois and Matthias Freiberger and Elias Najarro and Sebastian Risi},
      year={2023},
      eprint={2302.05981},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
```


### Retrieval-Augmented Generation (RAG)


#### Retrieval-Augmented Generation for Large Language Models: A Survey [`UNREAD`]

paper link: [here](https://arxiv.org/pdf/2312.10997.pdf)

github link: [here](https://github.com/Tongji-KGLLM/RAG-Survey)

citation:
```bibtex
@misc{gao2024retrievalaugmented,
      title={Retrieval-Augmented Generation for Large Language Models: A Survey}, 
      author={Yunfan Gao and Yun Xiong and Xinyu Gao and Kangxiang Jia and Jinliu Pan and Yuxi Bi and Yi Dai and Jiawei Sun and Qianyu Guo and Meng Wang and Haofen Wang},
      year={2024},
      eprint={2312.10997},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```


#### Precise Zero-Shot Dense Retrieval without Relevance Labels (HyDE) [`READ`]

paper link: [here](https://arxiv.org/pdf/2212.10496.pdf)

citation:
```bibtex
@misc{gao2022precise,
      title={Precise Zero-Shot Dense Retrieval without Relevance Labels}, 
      author={Luyu Gao and Xueguang Ma and Jimmy Lin and Jamie Callan},
      year={2022},
      eprint={2212.10496},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}
```


#### Generate rather than retrieve: Large language models are strong context generators (GenRead) [`READ`]

paper link: [here](https://arxiv.org/pdf/2209.10063)

tutorial links:

|tutorial name|public date|main-lib version|notebook link|
|-|-|-|-|
|tutorial_llamaindex_rag_api|2024.01|llama-index=0.9.26|[here](../notebooks/tutorial_llamaindex_rag_api.ipynb)|
|tutorial_langchain|2023.12|langchain=0.0.352, openai=1.6.1|[here](../notebooks/tutorial_langchain.ipynb)|

citation: 
```bibtex
@article{yu2022generate,
  title={Generate rather than retrieve: Large language models are strong context generators},
  author={Yu, Wenhao and Iter, Dan and Wang, Shuohang and Xu, Yichong and Ju, Mingxuan and Sanyal, Soumya and Zhu, Chenguang and Zeng, Michael and Jiang, Meng},
  journal={arXiv preprint arXiv:2209.10063},
  year={2022}
}
```


#### Pseudo Relevance Feedback with Deep Language Models and Dense Retrievers: Successes and Pitfalls (PRF) [`UNREAD`]

paper link: [here](https://arxiv.org/pdf/2108.11044.pdf)

citation:
```bibtex
@misc{li2022pseudo,
      title={Pseudo Relevance Feedback with Deep Language Models and Dense Retrievers: Successes and Pitfalls}, 
      author={Hang Li and Ahmed Mourad and Shengyao Zhuang and Bevan Koopman and Guido Zuccon},
      year={2022},
      eprint={2108.11044},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}
```


#### Retrieval-augmented generation for knowledge-intensive nlp tasks (RAG) [`READ`]

paper link: [here](https://proceedings.neurips.cc/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf)

citation: 
```bibtex
@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}
```
    
### Motion Generation 


#### MotionGPT: Human Motion as a Foreign Language [`UNREAD`]

paper link: [here](https://arxiv.org/pdf/2306.14795)

citation: 
```bibtex
@article{jiang2023motiongpt,
  title={MotionGPT: Human Motion as a Foreign Language},
  author={Jiang, Biao and Chen, Xin and Liu, Wen and Yu, Jingyi and Yu, Gang and Chen, Tao},
  journal={arXiv preprint arXiv:2306.14795},
  year={2023}
}
```
    