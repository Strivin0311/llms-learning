# LLMs for Embodied Intelligence
*Here're some resources about LLMs for Embodied Intelligence, espeicially robotics*


#### RoboGen: Towards Unleashing Infinite Data for Automated Robot Learning via Generative Simulation

tag: `RoboGen` | `ICML24` | `CMU`

paper link: [here](https://arxiv.org/pdf/2311.01455.pdf)

code link: [here](https://github.com/Genesis-Embodied-AI/RoboGen)

homepage link: [here](https://robogen-ai.github.io/)

citation:

```bibtex
@misc{wang2023robogen,
      title={RoboGen: Towards Unleashing Infinite Data for Automated Robot Learning via Generative Simulation}, 
      author={Yufei Wang and Zhou Xian and Feng Chen and Tsun-Hsuan Wang and Yian Wang and Katerina Fragkiadaki and Zackory Erickson and David Held and Chuang Gan},
      year={2023},
      eprint={2311.01455},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}
```


#### Towards end-to-end embodied decision making via multi-modal large language model: Explorations with gpt4-vision and beyond

tag: `World Model` | `NIPS23` | `Tecent Cloud AI` | `Peking University`

paper link: [here](https://arxiv.org/pdf/2310.02071)

code link: [here](https://github.com/pkunlp-icler/PCA-EVAL)

citation:

```bibtex
@article{chen2023towards,
  title={Towards end-to-end embodied decision making via multi-modal large language model: Explorations with gpt4-vision and beyond},
  author={Chen, Liang and Zhang, Yichi and Ren, Shuhuai and Zhao, Haozhe and Cai, Zefan and Wang, Yuchi and Wang, Peiyi and Liu, Tianyu and Chang, Baobao},
  journal={arXiv preprint arXiv:2310.02071},
  year={2023}
}
```

#### Language Models Meet World Models: Embodied Experiences Enhance Language Models

tag: `World Model` | `NIPS23` | `UCSD`

paper link: [here](https://arxiv.org/pdf/2305.10626)

code link: [here](https://github.com/szxiangjn/world-model-for-language-model)

citation:

```bibtex
@article{xiang2023language,
  title={Language Models Meet World Models: Embodied Experiences Enhance Language Models},
  author={Xiang, Jiannan and Tao, Tianhua and Gu, Yi and Shu, Tianmin and Wang, Zirui and Yang, Zichao and Hu, Zhiting},
  journal={arXiv preprint arXiv:2305.10626},
  year={2023}
}
```


#### Progprompt: Generating situated robot task plans using large language models

tag: `Progprompt` | `ICRA23` | `Nvidia`

paper link: [here](https://arxiv.org/pdf/2209.11302)

code link: [here](https://github.com/NVlabs/progprompt-vh)

homepage link: [here](https://progprompt.github.io/)

citation:

```bibtex
@inproceedings{singh2023progprompt,
  title={Progprompt: Generating situated robot task plans using large language models},
  author={Singh, Ishika and Blukis, Valts and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Thomason, Jesse and Garg, Animesh},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={11523--11530},
  year={2023},
  organization={IEEE}
}
```


#### Language models as zero-shot planners: Extracting actionable knowledge for embodied agents

tag: `Language Planner` | `ICML22` | `UC Berkeley`

paper link: [here](https://proceedings.mlr.press/v162/huang22a/huang22a.pdf)

code link: [here](https://github.com/huangwl18/language-planner)

homepage link: [here](https://wenlong.page/language-planner/)

citation:

```bibtex
@inproceedings{huang2022language,
  title={Language models as zero-shot planners: Extracting actionable knowledge for embodied agents},
  author={Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  booktitle={International Conference on Machine Learning},
  pages={9118--9147},
  year={2022},
  organization={PMLR}
}
```
    