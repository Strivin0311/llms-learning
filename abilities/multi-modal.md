# Multi-Modal Representation Abilities of LLMs
*Here're some resources about improving Multi-Modal Representation Abilities of LLMs*


### Video

#### CAST: Cross-Attention in Space and Time for Video Action Recognition ['UNREAD']

paper link: [here](https://arxiv.org/pdf/2311.18825.pdf)

citation: 
```bibtex
@misc{lee2023cast,
      title={CAST: Cross-Attention in Space and Time for Video Action Recognition}, 
      author={Dongho Lee and Jongseo Lee and Jinwoo Choi},
      year={2023},
      eprint={2311.18825},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

#### Free-bloom: Zero-shot text-to-video generator with llm director and ldm animator [`UNREAD`]

paper link: [here](https://arxiv.org/pdf/2309.14494)

citation: 
```bibtex
@article{huang2023free,
  title={Free-bloom: Zero-shot text-to-video generator with llm director and ldm animator},
  author={Huang, Hanzhuo and Feng, Yufan and Shi, Cheng and Xu, Lan and Yu, Jingyi and Yang, Sibei},
  journal={arXiv preprint arXiv:2309.14494},
  year={2023}
}
```
    


### Image

#### Visual instruction tuning [`UNREAD`]

paper link: [here](https://arxiv.org/pdf/2304.08485)

citation: 
```bibtex
@article{liu2023visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2304.08485},
  year={2023}
}
```
    

#### Visual programming: Compositional visual reasoning without training [`READ`]

paper link: [here](https://openaccess.thecvf.com/content/CVPR2023/papers/Gupta_Visual_Programming_Compositional_Visual_Reasoning_Without_Training_CVPR_2023_paper.pdf)

citation: 
```bibtex
@inproceedings{gupta2023visual,
  title={Visual programming: Compositional visual reasoning without training},
  author={Gupta, Tanmay and Kembhavi, Aniruddha},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14953--14962},
  year={2023}
}
```