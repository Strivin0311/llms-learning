# Miscellaneous Models
*Here's some resources about Miscellaneous Models*



#### Orca 2: Teaching Small Language Models How to Reason ['UNREAD']

paper link: [here](https://arxiv.org/pdf/2311.11045.pdf)

model links: 

|model name|link|
|-|-|
|Orca-2-13b|[here](https://huggingface.co/microsoft/Orca-2-13b)|
|Orca-2-7b|[here]|(https://huggingface.co/microsoft/Orca-2-7b)|

citation:
```bibtex
@misc{mitra2023orca,
      title={Orca 2: Teaching Small Language Models How to Reason}, 
      author={Arindam Mitra and Luciano Del Corro and Shweti Mahajan and Andres Codas and Clarisse Simoes and Sahaj Agarwal and Xuxi Chen and Anastasia Razdaibiedina and Erik Jones and Kriti Aggarwal and Hamid Palangi and Guoqing Zheng and Corby Rosset and Hamed Khanpour and Ahmed Awadallah},
      year={2023},
      eprint={2311.11045},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
```


#### Gemini: A Family of Highly Capable Multimodal Models ['UNREAD']

paper link: [here](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf)

citation:
```bibtex
 @article{gemini23google, 
    title={Gemini: A Family of Highly Capable Multimodal Models}, 
    url={https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf}, 
    author={Gemini Team, Google},
    year={2023}, 
    month={Dec}, 
    pages={62}
 }
```


#### Starling-7B- Increasing LLM Helpfulness & Harmlessness with RLAIF ['UNREAD']

blog link: [here](https://starling.cs.berkeley.edu/)

model links: 

|model name|link|
|-|-|
|Starling-LM-7B-alpha|[here](https://huggingface.co/berkeley-nest/Starling-LM-7B-alpha)|
|Starling-RM-7B-alpha|[here](https://huggingface.co/berkeley-nest/Starling-RM-7B-alpha)|


citation: 
```bibtex
@misc{starling2023,
    title = {Starling-7B: Improving LLM Helpfulness & Harmlessness with RLAIF},
    author = {Zhu, Banghua and Frick, Evan and Wu, Tianhao and Zhu, Hanlin and Jiao, Jiantao},
    month = {November},
    year = {2023}
}
```

#### Mixtral of experts: A high quality Sparse Mixture-of-Experts ['UNREAD']

blog link: [here](https://mistral.ai/news/mixtral-of-experts/)

model links: 

|model name|link|
|-|-|
|Mixtral-SlimOrca-8x7B|[here](https://huggingface.co/Open-Orca/Mixtral-SlimOrca-8x7B)|
|Mixtral-8x7B-Instruct-v0.1|[here](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)|
|Mixtral-8x7B-v0.1|[here](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1)|

citation:
```bibtex
@online{mixtral_model,
  author = {Mistral AI},
  title = {Mixtral of Experts: A High-Quality Sparse Mixture-of-Experts},
  year = {2023},
  url = {\url{https://mistral.ai/news/mixtral-of-experts/}}
}
```


#### Mistral 7B [`UNREAD`]

paper link: [here](https://arxiv.org/pdf/2310.06825.pdf)

model links: 

|model name|link|
|-|-|
|Mistral-7B-OpenOrca|[here](https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca)|
|Zephyr-7B-beta|[here](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta)|
|OpenHermes-2.5-Mistral-7B|[here](https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B)|
|OpenHermes-2.5-neural-chat-7b-v3-1-7B|[here](https://huggingface.co/Weyaxi/OpenHermes-2.5-neural-chat-7b-v3-1-7B)|
|Neural-Chat-7b-v3-1|[here](https://huggingface.co/Intel/neural-chat-7b-v3-1)|
|Mistral-7B-Instruct-v0.1|[here](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1)|
|Mistral-7B-v0.1|[here](https://huggingface.co/mistralai/Mistral-7B-v0.1)|



citation: 
```bibtex
@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}
```


#### OpenChat: Advancing Open-source Language Models with Mixed-Quality Data ['UNREAD']

paper link: [here](https://arxiv.org/pdf/2309.11235.pdf)

model link: 

|model name|link|
|-|-|
|OpenChat3.5|[here](https://huggingface.co/openchat/openchat_3.5)|
|OpenChat3.5-1210|[here](https://huggingface.co/openchat/openchat-3.5-1210)|
|||


citation:
```bibtex
@article{wang2023openchat,
  title={Openchat: Advancing open-source language models with mixed-quality data},
  author={Wang, Guan and Cheng, Sijie and Zhan, Xianyuan and Li, Xiangang and Song, Sen and Liu, Yang},
  journal={arXiv preprint arXiv:2309.11235},
  year={2023}
}
```
    


#### Baize: An open-source chat model with parameter-efficient tuning on self-chat data [`UNREAD`]

paper link: [here](https://arxiv.org/pdf/2304.01196)

citation: 
```bibtex
@article{xu2023baize,
  title={Baize: An open-source chat model with parameter-efficient tuning on self-chat data},
  author={Xu, Canwen and Guo, Daya and Duan, Nan and McAuley, Julian},
  journal={arXiv preprint arXiv:2304.01196},
  year={2023}
}
```


#### Flamingo: a visual language model for few-shot learning [`UNREAD`]

paper link: [here](https://proceedings.neurips.cc/paper_files/paper/2022/file/960a172bc7fbf0177ccccbb411a7d800-Paper-Conference.pdf)

citation: 
```bibtex
@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}
```


#### Opt: Open pre-trained transformer language models [`UNREAD`]

paper link: [here](https://arxiv.org/pdf/2205.01068.pdf?fbclid=IwAR1_0YiQKgxIsy8unzoLvL9E2OA41_kze-H0YvhoCzIQUp_gk-MR9dUs2ZE)

citation: 
```bibtex
@article{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}
```
    

#### Pangu-weather: A 3d high-resolution model for fast and accurate global weather forecast [`UNREAD`]

paper link: [here](https://arxiv.org/pdf/2211.02556)

citation: 
```bibtex
@article{bi2022pangu,
  title={Pangu-weather: A 3d high-resolution model for fast and accurate global weather forecast},
  author={Bi, Kaifeng and Xie, Lingxi and Zhang, Hengheng and Chen, Xin and Gu, Xiaotao and Tian, Qi},
  journal={arXiv preprint arXiv:2211.02556},
  year={2022}
}
```


#### Learning transferable visual models from natural language supervision (CLIP) [`UNREAD`]

paper link: [here](http://proceedings.mlr.press/v139/radford21a/radford21a.pdf)

citation: 
```bibtex
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}
```
    

#### LaMDA: Language Models for Dialog Applications ['UNREAD']

paper link: [here](https://arxiv.org/pdf/2201.08239.pdf)

citation:
```bibtex
@misc{thoppilan2022lamda,
      title={LaMDA: Language Models for Dialog Applications}, 
      author={Romal Thoppilan and Daniel De Freitas and Jamie Hall and Noam Shazeer and Apoorv Kulshreshtha and Heng-Tze Cheng and Alicia Jin and Taylor Bos and Leslie Baker and Yu Du and YaGuang Li and Hongrae Lee and Huaixiu Steven Zheng and Amin Ghafouri and Marcelo Menegali and Yanping Huang and Maxim Krikun and Dmitry Lepikhin and James Qin and Dehao Chen and Yuanzhong Xu and Zhifeng Chen and Adam Roberts and Maarten Bosma and Vincent Zhao and Yanqi Zhou and Chung-Ching Chang and Igor Krivokon and Will Rusch and Marc Pickett and Pranesh Srinivasan and Laichee Man and Kathleen Meier-Hellstern and Meredith Ringel Morris and Tulsee Doshi and Renelito Delos Santos and Toju Duke and Johnny Soraker and Ben Zevenbergen and Vinodkumar Prabhakaran and Mark Diaz and Ben Hutchinson and Kristen Olson and Alejandra Molina and Erin Hoffman-John and Josh Lee and Lora Aroyo and Ravi Rajakumar and Alena Butryna and Matthew Lamm and Viktoriya Kuzmina and Joe Fenton and Aaron Cohen and Rachel Bernstein and Ray Kurzweil and Blaise Aguera-Arcas and Claire Cui and Marian Croak and Ed Chi and Quoc Le},
      year={2022},
      eprint={2201.08239},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```