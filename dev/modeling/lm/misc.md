# Miscellaneous Architectures for language/sequence modeling
*Here're some resources about Miscellaneous Architectures for language/sequence modeling*


#### Kolmogorov-Arnold Transformer

tag: `KAT`

paper link: [here](https://arxiv.org/pdf/2409.10594)

github link: [here](https://github.com/Adamdad/kat)

citation:

```bibtex
@misc{yang2024kolmogorovarnoldtransformer,
      title={Kolmogorov-Arnold Transformer}, 
      author={Xingyi Yang and Xinchao Wang},
      year={2024},
      eprint={2409.10594},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.10594}, 
}
```


#### Scalable MatMul-free Language Modeling

tag: `Matmul-free LM`

paper link: [here](https://arxiv.org/pdf/2406.02528)

github link: [here](https://github.com/ridgerchu/matmulfreellm)

citation:

```bibtex
@misc{zhu2024scalablematmulfreelanguagemodeling,
      title={Scalable MatMul-free Language Modeling}, 
      author={Rui-Jie Zhu and Yu Zhang and Ethan Sifferman and Tyler Sheaves and Yiqiao Wang and Dustin Richmond and Peng Zhou and Jason K. Eshraghian},
      year={2024},
      eprint={2406.02528},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
      url={https://arxiv.org/abs/2406.02528}, 
}
```


#### Monarch Mixer: A simple sub-quadratic GEMM-based architecture

tag: `M2` | `Monarch Mixer`

paper link: [here](https://arxiv.org/pdf/2310.12109)

citation: 

```bibtex
@article{fu2023monarch,
  title={Monarch Mixer: A simple sub-quadratic GEMM-based architecture},
  author={Fu, Daniel Y and Arora, Simran and Grogan, Jessica and Johnson, Isys and Eyuboglu, Sabri and Thomas, Armin W and Spector, Benjamin and Poli, Michael and Rudra, Atri and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:2310.12109},
  year={2023}
}
```


#### An Attention Free Transformer

tag: `AFT`

paper link: [here](https://arxiv.org/pdf/2105.14103)

citation:

```bibtex
@misc{zhai2021attentionfreetransformer,
      title={An Attention Free Transformer}, 
      author={Shuangfei Zhai and Walter Talbott and Nitish Srivastava and Chen Huang and Hanlin Goh and Ruixiang Zhang and Josh Susskind},
      year={2021},
      eprint={2105.14103},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2105.14103}, 
}
```