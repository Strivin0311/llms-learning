# Text-to-Audio and Audio-to-Text
*Here're are some resources about Text-to-Audio and Audio-to-Text modeling, understanding, generation in Multi-Modal LLMs*


## Methods

#### Qwen2-Audio Technical Report

tag: `Qwen2-Audio`

paper link: [here](https://arxiv.org/pdf/2407.10759)

github link: [here](https://github.com/QwenLM/Qwen2-Audio)

model links:

|model name|link|
|-|-|
|Qwen2-Audio-7B-Instruct|[here](https://huggingface.co/Qwen/Qwen2-Audio-7B-Instruct)|
|Qwen2-Audio-7B|[here](https://huggingface.co/Qwen/Qwen2-Audio-7B)|

citation:

```bibtex
@misc{chu2024qwen2audiotechnicalreport,
      title={Qwen2-Audio Technical Report}, 
      author={Yunfei Chu and Jin Xu and Qian Yang and Haojie Wei and Xipin Wei and Zhifang Guo and Yichong Leng and Yuanjun Lv and Jinzheng He and Junyang Lin and Chang Zhou and Jingren Zhou},
      year={2024},
      eprint={2407.10759},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2407.10759}, 
}
```


## Benchmarks


#### AIR-Bench: Benchmarking Large Audio-Language Models via Generative Comprehension

tag: `AIR-Bench`

paper link: [here](https://arxiv.org/pdf/2402.07729)

github link: [here](https://github.com/OFA-Sys/AIR-Bench)

citation:

```bibtex
@misc{yang2024airbenchbenchmarkinglargeaudiolanguage,
      title={AIR-Bench: Benchmarking Large Audio-Language Models via Generative Comprehension}, 
      author={Qian Yang and Jin Xu and Wenrui Liu and Yunfei Chu and Ziyue Jiang and Xiaohuan Zhou and Yichong Leng and Yuanjun Lv and Zhou Zhao and Chang Zhou and Jingren Zhou},
      year={2024},
      eprint={2402.07729},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2402.07729}, 
}
```