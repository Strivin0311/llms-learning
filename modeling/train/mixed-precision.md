# Mixed-Precision Training
*Here're some resources about Mixed-Precision strategies for LLMs training*



#### FP8-LM: Training FP8 Large Language Models [`READ`]

paper link: [here](https://arxiv.org/pdf/2310.18313.pdf)

github link: [here](https://github.com/Azure/MS-AMP)

citation:
```bibtex
@misc{peng2023fp8lm,
      title={FP8-LM: Training FP8 Large Language Models}, 
      author={Houwen Peng and Kan Wu and Yixuan Wei and Guoshuai Zhao and Yuxiang Yang and Ze Liu and Yifan Xiong and Ziyue Yang and Bolin Ni and Jingcheng Hu and Ruihang Li and Miaosen Zhang and Chen Li and Jia Ning and Ruizhe Wang and Zheng Zhang and Shuguang Liu and Joe Chau and Han Hu and Peng Cheng},
      year={2023},
      eprint={2310.18313},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
```


#### BitNet: Scaling 1-bit Transformers for Large Language Models [`READ`]

paper link: [here](https://arxiv.org/pdf/2310.11453)

blog link: [here](https://thegenerality.com/agi/)

github link: [here](https://github.com/microsoft/unilm)

citation:
```bibtex
@misc{wang2023bitnet,
      title={BitNet: Scaling 1-bit Transformers for Large Language Models}, 
      author={Hongyu Wang and Shuming Ma and Li Dong and Shaohan Huang and Huaijie Wang and Lingxiao Ma and Fan Yang and Ruiping Wang and Yi Wu and Furu Wei},
      year={2023},
      eprint={2310.11453},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```


#### Training and inference of large language models using 8-bit floating point [`READ`]

paper link: [here](https://arxiv.org/pdf/2309.17224)

citation:
```bibtex
@misc{perez2023training,
      title={Training and inference of large language models using 8-bit floating point}, 
      author={Sergio P. Perez and Yan Zhang and James Briggs and Charlie Blake and Josh Levy-Kramer and Paul Balanca and Carlo Luschi and Stephen Barlow and Andrew William Fitzgibbon},
      year={2023},
      eprint={2309.17224},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
```


#### Mixed Precision Training [`READ`]

paper link: [here](https://arxiv.org/pdf/1710.03740)

citation:
```bibtex
@misc{micikevicius2018mixed,
      title={Mixed Precision Training}, 
      author={Paulius Micikevicius and Sharan Narang and Jonah Alben and Gregory Diamos and Erich Elsen and David Garcia and Boris Ginsburg and Michael Houston and Oleksii Kuchaiev and Ganesh Venkatesh and Hao Wu},
      year={2018},
      eprint={1710.03740},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
```