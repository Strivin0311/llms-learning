# Survey on LLMs
*Here's some resources about Survey on LLMs*


## Paper


#### Towards Efficient Generative Large Language Model Serving: A Survey from Algorithms to Systems [`UNREAD`]

paper link: [here](https://arxiv.org/pdf/2312.15234.pdf)

citation:
```bibtex
@misc{miao2023efficient,
      title={Towards Efficient Generative Large Language Model Serving: A Survey from Algorithms to Systems}, 
      author={Xupeng Miao and Gabriele Oliaro and Zhihao Zhang and Xinhao Cheng and Hongyi Jin and Tianqi Chen and Zhihao Jia},
      year={2023},
      eprint={2312.15234},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
```

#### Challenges and applications of large language models [`UNREAD`]

paper link: [here](https://arxiv.org/pdf/2307.10169)

citation: 
```bibtex
@article{kaddour2023challenges,
  title={Challenges and applications of large language models},
  author={Kaddour, Jean and Harris, Joshua and Mozes, Maximilian and Bradley, Herbie and Raileanu, Roberta and McHardy, Robert},
  journal={arXiv preprint arXiv:2307.10169},
  year={2023}
}
```
    


#### A comprehensive overview of large language models [`UNREAD`]

paper link: [here](https://arxiv.org/pdf/2307.06435)

citation: 
```bibtex
@article{naveed2023comprehensive,
  title={A comprehensive overview of large language models},
  author={Naveed, Humza and Khan, Asad Ullah and Qiu, Shi and Saqib, Muhammad and Anwar, Saeed and Usman, Muhammad and Barnes, Nick and Mian, Ajmal},
  journal={arXiv preprint arXiv:2307.06435},
  year={2023}
}
```
    


#### ChatGPT: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope [`READ`]

paper link: [here](https://www.sciencedirect.com/science/article/pii/S266734522300024X)

citation: 
```bibtex
@article{ray2023chatgpt,
  title={ChatGPT: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope},
  author={Ray, Partha Pratim},
  journal={Internet of Things and Cyber-Physical Systems},
  year={2023},
  publisher={Elsevier}
}
```
    


#### Augmented language models: a survey [`UNREAD`]

paper link: [here](https://arxiv.org/pdf/2302.07842)

citation: 
```bibtex
@article{mialon2023augmented,
  title={Augmented language models: a survey},
  author={Mialon, Gr{\'e}goire and Dess{\`\i}, Roberto and Lomeli, Maria and Nalmpantis, Christoforos and Pasunuru, Ram and Raileanu, Roberta and Rozi{\`e}re, Baptiste and Schick, Timo and Dwivedi-Yu, Jane and Celikyilmaz, Asli and others},
  journal={arXiv preprint arXiv:2302.07842},
  year={2023}
}
```

#### Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning [`READ`]

blog link: [here](https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/)

citation:
```bibtex
@misc{Dettmers2023WhichGPU,
  author = {Tim Dettmers},
  title = {Which GPU for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning},
  year = {2023},
  month = {Jan},
  howpublished = {\url{https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/}},
}
```
    


## Textbook

#### What Are ChatGPT and Its Friends [`UNREAD`]

book link: [here](https://pan.baidu.com/s/1ttXkaG2Y5G48j4vw5g7gYg), with extraction code: `vva7`


