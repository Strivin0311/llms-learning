# llms-learning

A repository sharing the literatures and resources about Large Language Models (LLMs)


## Table of Contents

* [Model Hubs](./model-hubs)
  * [Foundation Models](./model-hubs/foundation)
    * [Baichuan](./model-hubs/foundation/baichuan.md)
    * [BART](./model-hubs/foundation/bart.md)
    * [BERT](./model-hubs/foundation/bert.md)
    * [Bloom](./model-hubs/foundation/bloom.md)
    * [Claude](./model-hubs/foundation/claude.md)
    * [ERNIE](./model-hubs/foundation/ernie.md)
    * [Gemini](./model-hubs/foundation/gemini.md)
    * [GLM](./model-hubs/foundation/glm.md)
    * [GPT](./model-hubs/foundation/gpt.md)
    * [Llama](./model-hubs/foundation/llama.md)
    * [Mistral](./model-hubs/foundation/mistral.md)
    * [PaLM](./model-hubs/foundation/palm.md)
    * [Qwen](./model-hubs/foundation/qwen.md)
    * [T5](./model-hubs/foundation/t5.md)
    * [Miscellaneous](./model-hubs/foundation/miscellaneous.md)
  * [Domain Specific Models](./model-hubs/domain-specific)
    * [Code LLMs](./model-hubs/domain-specific/code.md)
    * [Financial LLMs](./model-hubs/domain-specific/finance.md)
    * [Math LLMs](./model-hubs/domain-specific/math.md)
* [Development Stages](./dev/)
  * [Training](./dev/train/)
    * [Pre-Training](./dev/train/pretrain.md)
      * [Efficient Pre-Training](./dev/train/pretrain.md#efficient-pretraining)
      * [Effective Pre-Training](./dev/train/pretrain.md#effective-pretraining)
      * [Pretraining Corpus](./dev/train/pretrain.md#pretraining-corpus)
      * [Pretraining Objectives](./dev/train/pretrain.md#pretraining-objectives)
    * [Parallelism](./dev/train/parallel.md)
      * [Integration of Parallelism](./dev/train/parallel.md#integration-of-parallelism)
      * [Expert Parallelism (EP)](./dev/train/parallel.md#expert-parallelism-ep)
      * [Context Parallelism (CP)](./dev/train/parallel.md#context-parallelism-cp)
      * [Pipeline Parallelism (PP)](./dev/train/parallel.md#pipeline-parallelism-pp)
      * [Sequence Parallelism (SP)](./dev/train/parallel.md#sequence-parallelism-sp)
      * [Tensor Parallelism (TP)](./dev/train/parallel.md#tensor-parallelism-tp)
      * [Data Parallelism (DP)](./dev/train/parallel.md#data-parallelism-dp)
    * [Mixed-Precision](./dev/train/mixed-precision.md)
    * [Optimizer](./dev/train/optimizer.md)
    * [Offloading](./dev/train/offload.md)
  * [Fine-Tuning](./dev/finetune/)
    * [Efficient Fine-Tuning](./dev/finetune/peft.md)
      * [PEFT](./dev/finetune/peft.md#parameter-efficient-fine-tuning-peft)
    * [Instruction Fine-Tuning (IFT)](./dev/finetune/instruction.md)
    * [Alignment](./dev/finetune/alignment.md)
  * [Post-Training](./dev/post-train/)
    * [Inference](./dev/post-train/inference.md)
      * [Efficient Inference](./dev/post-train/inference.md#efficient-inference)
      * [Effective Decoding](./dev/post-train/inference.md#effective-decoding)
      * [Calibration](./dev/post-train/inference.md#calibration)
    * [Evaluation](./dev/post-train/eval.md)
      * [Benchmarking](./dev/post-train/eval.md#benchmarking)
      * [English Benchmarks](./dev/post-train/eval.md#english-benchmarks)
      * [Chinese Benchmarks](./dev/post-train/eval.md#chinese-benchmarks)
      * [Multi-Language Benchmarks](./dev/post-train/eval.md#multi-language-benchmarks)
      * [Metrics](./dev/post-train/eval.md#metrics)
    * [Deployment](./dev/post-train/deploy.md)
  * [Weight Compression](./dev/compress/)
    * [Pruning](./dev/compress/pruning.md)
    * [Quantization](./dev/compress/quantization.md)
  * [Architecture](./dev/modeling/)
    * [Mixture of Experts (MoE)](./dev/modeling/mixture-of-experts.md)
    * [Activation Functions](./dev/modeling/activation-func.md)
* [Abilities](./abilities/)
  * [In-Context Learning (ICL)](./abilities/in-context.md)
  * [Long context](./abilities/long-context.md)
  * [Multi Modal](./abilities/multi-modal.md)
  * [Reasoning](./abilities/reasoning.md)
  * [Emergence](./abilities/emergence.md)
  * [Robustness](./abilities/robust.md)
  * [Model Editing](./abilities/edit.md)
* [Applications](./app/)
  * [LLMs as Agent](./app/agent.md)
  * [LLMs for Embodied AI](./app/embodied.md)
  * [LLMs powered Generation](./app/gen.md)
  * [LLMs as Tool Caller](./app/tool.md)
* [Survey](./survey.md)
* [Tutorials](./tutorial.md)





## More to Learn

* This repo is a sub-repo for my [dgm-learning](https://github.com/Strivin0311/dgm-learning) repo, where you can learn more technologies about the deep generative models.
* I've also built another sub-repo [long-llms-learning](https://github.com/Strivin0311/long-llms-learning), to specifically share the literature about how to model and evaluate the long-context capabilities of LLMs, with a survey paper attached.
* I've also built another sub-repo [mmlms-learning](https://github.com/Strivin0311/mmlms-learning), to specifically share the literature about Multi-Modal Language Modeles (MMLMs).
