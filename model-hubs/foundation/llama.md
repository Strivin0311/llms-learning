# Llama
*Here're some resources about Llama*


#### The Llama 3 Herd of Models

paper link: [here](https://scontent-nrt1-2.xx.fbcdn.net/v/t39.2365-6/452387774_1036916434819166_4173978747091533306_n.pdf?_nc_cat=104&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=t6egZJ8QdI4Q7kNvgGe0d3N&_nc_ht=scontent-nrt1-2.xx&oh=00_AYCycEIul53gqCvm5rnsI2IDC5842Ip5NBDPpnXIoWZmVw&oe=66A60A8D)

blog link: [llama-3](https://ai.meta.com/blog/meta-llama-3/) | [llama-3.1](https://ai.meta.com/blog/meta-llama-3-1/)

github link: [here](https://github.com/meta-llama/llama3)

model links:

|model name|link|
|-|-|
|Meta-Llama-3.1-405B-Instruct-FP8|[here](https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct-FP8)|
|Meta-Llama-3.1-405B-FP8|[here](https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-FP8)|
|Meta-Llama-3.1-405B-Instruct|[here](https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct)|
|Meta-Llama-3.1-405B|[here](https://huggingface.co/meta-llama/Meta-Llama-3.1-405B)|
|Meta-Llama-3.1-70B-Instruct|[here](https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct)|
|Meta-Llama-3.1-70B|[here](https://huggingface.co/meta-llama/Meta-Llama-3.1-70B)|
|Meta-Llama-3.1-8B-Instruct|[here](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct)|
|Meta-Llama-3.1-8B|[here](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B)|
|Meta-Llama-3-70B-Instruct|[here](https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct)|
|Meta-Llama-3-70B|[here](https://huggingface.co/meta-llama/Meta-Llama-3-70B)|
|Meta-Llama-3-8B-Instruct|[here](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)|
|Meta-Llama-3-8B|[here](https://huggingface.co/meta-llama/Meta-Llama-3-8B)|

citation:

```bibtex
@article{llama3modelcard,
  title={Llama 3 Model Card},
  author={AI@Meta},
  year={2024},
  url = {https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md}
}
```

#### Llama 2: Open foundation and fine-tuned chat models

paper link: [here](https://arxiv.org/pdf/2307.09288.pdf)

model links: 

|model name|link|
|-|-|
|Llama2-70b-chat-hf|[here](https://huggingface.co/meta-llama/Llama-2-70b-chat-hf)|
|Llama2-70b-hf|[here](https://huggingface.co/meta-llama/Llama-2-70b-hf)|
|Llama2-13b-chat-hf|[here](https://huggingface.co/meta-llama/Llama-2-13b-chat-hf)|
|Llama2-13b-hf|[here](https://huggingface.co/meta-llama/Llama-2-13b-hf)|
|Llama2-7b-chat-hf|[here](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf)|
|Llama2-7b-hf|[here](https://huggingface.co/meta-llama/Llama-2-7b-hf)|

citation: 
```bibtex
@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}
```


#### WizardLM: Empowering Large Language Models to Follow Complex Instructions

paper link: [here](https://arxiv.org/pdf/2304.12244.pdf)

github link: [here](https://github.com/nlpxucan/WizardLM)

model links: 

|model name|link|
|-|-|
|WizardLM-7B-V1.0|[here](https://huggingface.co/WizardLM/WizardLM-7B-V1.0)|
|WizardLM-13B-V1.1|[here](https://huggingface.co/WizardLM/WizardLM-13B-V1.1)|
|WizardLM-13B-V1.2|[here](https://huggingface.co/WizardLM/WizardLM-13B-V1.2)|
|WizardLM-70B-V1.0|[here](https://huggingface.co/WizardLM/WizardLM-70B-V1.0)|

citation:
```bibtex
@misc{xu2023wizardlm,
      title={WizardLM: Empowering Large Language Models to Follow Complex Instructions}, 
      author={Can Xu and Qingfeng Sun and Kai Zheng and Xiubo Geng and Pu Zhao and Jiazhan Feng and Chongyang Tao and Daxin Jiang},
      year={2023},
      eprint={2304.12244},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```
    

#### Llama: Open and efficient foundation language models

paper link: [here](https://arxiv.org/pdf/2302.13971)

citation: 
```bibtex
@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}
```
    