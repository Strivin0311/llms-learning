# Evaluation on Synthetic Language Modeling Capabilities of LLMs
*Here's some resources about Evaluation on Synthetic Language Modeling Capabilities of LLMs*


## Benchmarks

#### GPT-Fathom- Benchmarking Large Language Models to Decipher the Evolutionary Path towards GPT-4 and Beyond ['READ']

paper link: [here](https://arxiv.org/pdf/2309.16583)

citation
```bibtex
@article{zheng2023gpt,
  title={GPT-Fathom: Benchmarking Large Language Models to Decipher the Evolutionary Path towards GPT-4 and Beyond},
  author={Zheng, Shen and Zhang, Yuyu and Zhu, Yijie and Xi, Chenguang and Gao, Pengyang and Zhou, Xun and Chang, Kevin Chen-Chuan},
  journal={arXiv preprint arXiv:2309.16583},
  year={2023}
}
```


#### Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena [`UNREAD`]

paper link: [here](https://arxiv.org/pdf/2306.05685.pdf)

homepage link (chatbot Arena): [here](https://chat.lmsys.org/)

citation:
```bibtex
@misc{zheng2023judging,
      title={Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric. P Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
      eprint={2306.05685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```


#### InstructEval: Towards Holistic Evaluation of Instruction-Tuned Large Language Models [`UNREAD`]

paper link: [here](https://arxiv.org/pdf/2306.04757.pdf)

citation: 
```bibtex
@misc{chia2023instructeval,
      title={INSTRUCTEVAL: Towards Holistic Evaluation of Instruction-Tuned Large Language Models}, 
      author={Yew Ken Chia and Pengfei Hong and Lidong Bing and Soujanya Poria},
      year={2023},
      eprint={2306.04757},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```
    


#### Holistic evaluation of language models (HELM) [`UNREAD`]

paper link: [here](https://arxiv.org/pdf/2211.09110.pdf)

citation: 
```bibtex
@article{liang2022holistic,
  title={Holistic evaluation of language models},
  author={Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others},
  journal={arXiv preprint arXiv:2211.09110},
  year={2022}
}
```
    



## Metrics

#### Language model evaluation beyond perplexity [`UNREAD`]

paper link: [here](https://arxiv.org/pdf/2106.00085)

citation: 
```bibtex
@article{meister2021language,
  title={Language model evaluation beyond perplexity},
  author={Meister, Clara and Cotterell, Ryan},
  journal={arXiv preprint arXiv:2106.00085},
  year={2021}
}
```
    