#### Norquinal/claude_multi_instruct_30k

data link: [here](https://huggingface.co/datasets/Norquinal/claude_multi_instruct_30k)

This dataset is an adapation of my previous [claude_multiround_chat_30k](https://huggingface.co/datasets/Norquinal/claude_multiround_chat_30k) dataset with only the first 30k instruction/response pairs and parsed into an instruct format.

The instructions were generated synethically using a method that can be tenatively described as "multi-instruct." These instructions consist of numerous discrete tasks that the AI has to work its way through, thereby hopefully increasing its comprehension and awareness of complex instructions.

The topics of the instruction ranged from STEM, Arts & Humanities, Social Knowledge, and General Knowledge.


#### Norquinal/claude_multi_instruct_1k

data link: [here](https://huggingface.co/datasets/Norquinal/claude_multi_instruct_1k)

This dataset is the result of roughly 1.2k instruction/response pairs generated by Claude, with instances of blatant alignment removed. 
1020 instructions remain.

The instructions were generated synethically using a method that can be tenatively described as "multi-instruct." These instructions consist of numerous discrete tasks that the AI has to work its way through, thereby hopefully increasing its comprehension and awareness of complex instructions. The instructions and responses were (albeit, hastily) manually reviewed to discard and adjust any failed prompts or incomplete responses.

The topics of the instructions range from:
 * Mathematics
 * Code generation
 * Writing
 * History
 * Computer Science
 * Reasoning
 * Code debugging
 * Multilingualism
 * Roleplay
 * Biology
 * Literature
 * Technology
 * Sports
 * Law
 * Medicine
 * Art
 * Music
 * Economics
 * Physics
 * Creativity
 * Storytelling
 * Anime
 * Movies
 * Video games and board games
 * Animals
 * Trivia

As you can see, there is a heavy bias towards writing and other creative endeavors. Given the small size of the dataset, this will likely reflect itself in finetuning.