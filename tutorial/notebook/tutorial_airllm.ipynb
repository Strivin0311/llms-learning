{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial on inference 70B LLM with 4GB single GPU based on AirLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is based on the previous blog: [here](https://pub.towardsai.net/make-any-llm-fit-any-gpu-in-10-lines-of-code-dba28eebf5ba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial runs successfully with: **airllm==2.8.3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step0. set up the environment and the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# run llama2 70b directly with 3 A6000, each of which has 48GB memory\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,3'\n",
    "\n",
    "# run llama2 70b through airllm with a single A6000\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "input_text = [\"Which team won the NBA Championship the year when Lebron James was born?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step1. runing Llama2-70b using airllm with a single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-13 08:19:51.452960: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-13 08:19:52.228609: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> bitsandbytes installed\n",
      ">>>> cache_utils installed\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "from airllm import AirLLMLlama2\n",
    "\n",
    "llama_root = os.getenv('LOCAL_LLAMA_MODEL_ROOT')\n",
    "llama_name = 'Llama2-70b-chat'\n",
    "\n",
    "# NOTE: airllm needs to split the model shards layer by layer and save it first before loading\n",
    "llama_layer_shard_saving_path = os.path.join('./model/airllm/split_mdoel/', llama_name)\n",
    "if not os.path.exists(llama_layer_shard_saving_path): os.makedirs(llama_layer_shard_saving_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_tokenizer = LlamaTokenizer.from_pretrained(os.path.join(llama_root, llama_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "263ddb6f786d4decb644c9d9ca8af3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 8192)\n",
       "    (layers): ModuleList(\n",
       "      (0-79): 80 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=8192, out_features=8192, bias=False)\n",
       "          (k_proj): Linear(in_features=8192, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=8192, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=8192, out_features=8192, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=8192, out_features=28672, bias=False)\n",
       "          (up_proj): Linear(in_features=8192, out_features=28672, bias=False)\n",
       "          (down_proj): Linear(in_features=28672, out_features=8192, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=8192, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama2_70b = LlamaForCausalLM.from_pretrained( # requiring 150G GPU memory\n",
    "    os.path.join(llama_root, llama_name),\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='auto',\n",
    ")\n",
    "llama2_70b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory footprint of Llama2-70b-chat is: 128 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"The memory footprint of {llama_name} is: {llama2_70b.get_memory_footprint() // 1024**3} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Lebron James was born on December 30, 1984. The NBA Championship that year was won by the Boston Celtics, who defeated the Los Angeles Lakers in the NBA Finals.\n"
     ]
    }
   ],
   "source": [
    "inputs = llama_tokenizer(\n",
    "    input_text,\n",
    "    return_tensors=\"pt\",\n",
    ").to('cuda')\n",
    "\n",
    "outputs = llama2_70b.generate( # it takes 10 seconds to generate 48 new tokens, with the speed of 4.8 token/s\n",
    "    **inputs,\n",
    "    max_new_tokens=128,\n",
    "    pad_token_id=llama_tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "output_text = llama_tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "print(output_text[len(input_text[0]):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found index file...\n",
      "found_layers:{'model.embed_tokens.': True, 'model.layers.0.': True, 'model.layers.1.': True, 'model.layers.2.': True, 'model.layers.3.': True, 'model.layers.4.': True, 'model.layers.5.': True, 'model.layers.6.': True, 'model.layers.7.': True, 'model.layers.8.': True, 'model.layers.9.': True, 'model.layers.10.': True, 'model.layers.11.': True, 'model.layers.12.': True, 'model.layers.13.': True, 'model.layers.14.': True, 'model.layers.15.': True, 'model.layers.16.': True, 'model.layers.17.': True, 'model.layers.18.': True, 'model.layers.19.': True, 'model.layers.20.': True, 'model.layers.21.': True, 'model.layers.22.': True, 'model.layers.23.': True, 'model.layers.24.': True, 'model.layers.25.': True, 'model.layers.26.': True, 'model.layers.27.': True, 'model.layers.28.': True, 'model.layers.29.': True, 'model.layers.30.': True, 'model.layers.31.': True, 'model.layers.32.': True, 'model.layers.33.': True, 'model.layers.34.': True, 'model.layers.35.': True, 'model.layers.36.': True, 'model.layers.37.': True, 'model.layers.38.': True, 'model.layers.39.': True, 'model.layers.40.': True, 'model.layers.41.': True, 'model.layers.42.': True, 'model.layers.43.': True, 'model.layers.44.': True, 'model.layers.45.': True, 'model.layers.46.': True, 'model.layers.47.': True, 'model.layers.48.': True, 'model.layers.49.': True, 'model.layers.50.': True, 'model.layers.51.': True, 'model.layers.52.': True, 'model.layers.53.': True, 'model.layers.54.': True, 'model.layers.55.': True, 'model.layers.56.': True, 'model.layers.57.': True, 'model.layers.58.': True, 'model.layers.59.': True, 'model.layers.60.': True, 'model.layers.61.': True, 'model.layers.62.': True, 'model.layers.63.': True, 'model.layers.64.': True, 'model.layers.65.': True, 'model.layers.66.': True, 'model.layers.67.': True, 'model.layers.68.': True, 'model.layers.69.': True, 'model.layers.70.': True, 'model.layers.71.': True, 'model.layers.72.': True, 'model.layers.73.': True, 'model.layers.74.': True, 'model.layers.75.': True, 'model.layers.76.': True, 'model.layers.77.': True, 'model.layers.78.': True, 'model.layers.79.': True, 'model.norm.': True, 'lm_head.': True}\n",
      "saved layers already found in model/airllm/split_mdoel/Llama2-70b-chat/splitted_model\n",
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<airllm.airllm.AirLLMLlama2 at 0x7fde4338f280>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cut original 29 shards into 83 shards layer by layer (about 3x)\n",
    "llama2_70b_airllm = AirLLMLlama2( \n",
    "    os.path.join(llama_root, llama_name),\n",
    "    layer_shards_saving_path=llama_layer_shard_saving_path,\n",
    ")\n",
    "llama2_70b_airllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory footprint of Llama2-70b-chat with airllm is: 1132 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"The memory footprint of {llama_name} with airllm is: \\\n",
    "{torch.cuda.memory_allocated(0) // 1024**2} MB\") # NOTE: the running memory peak is about 2.7GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [02:10<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:42<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:22<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:22<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:20<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:17<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:20<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:21<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:23<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:22<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:22<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:22<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:20<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:21<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:20<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:20<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:20<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:20<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:21<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:21<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:18<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:22<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:22<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:23<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:22<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:22<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:21<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:20<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:20<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:19<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:20<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:21<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:20<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:20<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:21<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:21<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:20<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:20<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:22<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:20<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:22<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:20<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:22<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:22<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:21<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new version of transfomer, no need to use BetterTransformer, try setting attn impl to sdpa...\n",
      "attn imp: <class 'transformers.models.llama.modeling_llama.LlamaSdpaAttention'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 83/83 [01:20<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# inference through layer by layer\n",
    "inputs = llama2_70b_airllm.tokenizer(\n",
    "    input_text,\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=False,\n",
    ").to('cuda')\n",
    "\n",
    "outputs = llama2_70b_airllm.generate( # it takes 67 minutes to generate 48 new tokens, with the speed of 1min-23s / token\n",
    "    inputs['input_ids'],\n",
    "    max_new_tokens=128,\n",
    "    use_cache=True,\n",
    "    return_dict_in_generate=True,\n",
    "    pad_token_id=llama2_70b_airllm.tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "output_text = llama2_70b_airllm.tokenizer.decode(\n",
    "    outputs['sequences'][0], skip_special_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which team won the NBA Championship the year when Lebron James was born?\n",
      "\n",
      "Lebron James was born on December 30, 1984. The NBA Championship that year was won by the Boston Celtics, who defeated the Los Angeles Lakers in the NBA Finals.\n"
     ]
    }
   ],
   "source": [
    "print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step2. run quantized mistral-7b with airllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-13 18:47:48.506550: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-13 18:47:50.890264: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> bitsandbytes installed\n",
      ">>>> cache_utils installed\n"
     ]
    }
   ],
   "source": [
    "from airllm import AirLLMMistral\n",
    "\n",
    "mistral_root = os.getenv('LOCAL_MISTRAL_MODEL_ROOT')\n",
    "\n",
    "mistral_name = 'Mistral-7B-v0.1'\n",
    "\n",
    "mistral_layer_shard_saving_path = os.path.join('./model/airllm/split_mdoel/', mistral_name)\n",
    "if not os.path.exists(mistral_layer_shard_saving_path): os.makedirs(mistral_layer_shard_saving_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found index file...\n",
      "found_layers:{'model.embed_tokens.': True, 'model.layers.0.': True, 'model.layers.1.': True, 'model.layers.2.': True, 'model.layers.3.': True, 'model.layers.4.': True, 'model.layers.5.': True, 'model.layers.6.': True, 'model.layers.7.': True, 'model.layers.8.': True, 'model.layers.9.': True, 'model.layers.10.': True, 'model.layers.11.': True, 'model.layers.12.': True, 'model.layers.13.': True, 'model.layers.14.': True, 'model.layers.15.': True, 'model.layers.16.': True, 'model.layers.17.': True, 'model.layers.18.': True, 'model.layers.19.': True, 'model.layers.20.': True, 'model.layers.21.': True, 'model.layers.22.': True, 'model.layers.23.': True, 'model.layers.24.': True, 'model.layers.25.': True, 'model.layers.26.': True, 'model.layers.27.': True, 'model.layers.28.': True, 'model.layers.29.': True, 'model.layers.30.': True, 'model.layers.31.': True, 'model.norm.': True, 'lm_head.': True}\n",
      "saved layers already found in model/airllm/split_mdoel/Mistral-7B-v0.1/splitted_model.4bit\n",
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n",
      "not support prefetching for compression for now. loading with no prepetching mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<airllm.airllm_mistral.AirLLMMistral at 0x7fcc319adc40>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral_7b_airllm = AirLLMMistral( # split 2 shards into 35 shards layer by layer\n",
    "    os.path.join(mistral_root, mistral_name),\n",
    "    layer_shards_saving_path=mistral_layer_shard_saving_path,\n",
    "    compression=\"4bit\", # 8bit is also supported\n",
    ")\n",
    "mistral_7b_airllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:26<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:11<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:11<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:11<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:11<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:11<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:11<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:11<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:11<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:11<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:11<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:11<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:11<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:11<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either BetterTransformer or attn_implementation='sdpa' is available, creating model directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running layers(self.running_device): 100%|██████████| 35/35 [00:10<00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------  response  -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = mistral_7b_airllm.tokenizer(\n",
    "    input_text, \n",
    "    return_tensors=\"pt\"\n",
    ").to('cuda')\n",
    "\n",
    "outputs = mistral_7b_airllm.generate( # it takes 25 minutes to generate 256 new tokens, with the speed of 6s / token\n",
    "    **inputs,\n",
    "    max_new_tokens=128,\n",
    "    pad_token_id=mistral_7b_airllm.tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "print(\"-\"*25, \" response \", \"-\"*25)\n",
    "output_text = mistral_7b_airllm.tokenizer.batch_decode(\n",
    "    outputs, \n",
    "    skip_special_tokens=True, \n",
    ")[0][len(input_text[0]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "## Which team won the NBA Championship the year when Lebron James was born?\n",
      "\n",
      "The Cleveland Cavaliers won the 2016 NBA Finals, defeating the Golden State Warriors in seven games.\n",
      "\n",
      "## Who won the NBA Championship in 2003?\n",
      "\n",
      "The San Antonio Spurs won the 2003 NBA Finals, defeating the New Jersey Nets in five games.\n",
      "\n",
      "## Who won the NBA Championship in 2004?\n",
      "\n",
      "The Detroit Pistons won the 2004 NBA Finals, defeating the Los\n"
     ]
    }
   ],
   "source": [
    "print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step3. try more models with airllm on your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airllm import AirLLMQWen\n",
    "\n",
    "from airllm import AirLLMBaichuan\n",
    "\n",
    "from airllm import AirLLMChatGLM\n",
    "\n",
    "from airllm import AirLLMInternLM\n",
    "\n",
    "from airllm import AirLLMMistral\n",
    "\n",
    "from airllm import AirLLMMixtral"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
