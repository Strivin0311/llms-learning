{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jkk8jWTHayS"
      },
      "source": [
        "## Local LLMs fine-tuning with different quantization techniques (`bitsandbytes` and `gptq`)\n",
        "\n",
        "This notebooks provide a quick overview of using various quantization techniques to fine-tune LLMs on comodity hardware (memory constrained). Especially on Colab GPU (free-tier), to fine-tune small LLM variant (7B) with 16GiB, quantization techniques like 4-bit quantization and GPTQ is needed to prevent Out-of-Memory errors with long sequences length."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLVZdYHNIRd5"
      },
      "source": [
        "Install prerequisite packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAkBhRxYhJ1R",
        "outputId": "defbf670-d1fa-4c90-9b2c-2d858caad9ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'llm_finetuning'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 61 (delta 13), reused 54 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (61/61), 84.66 KiB | 1.76 MiB/s, done.\n",
            "/content/llm_finetuning\n",
            "Collecting git+https://github.com/huggingface/peft.git (from -r requirements.txt (line 14))\n",
            "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-on1mg_ot\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-on1mg_ot\n",
            "  Resolved https://github.com/huggingface/peft.git to commit 06fd06a4d2e8ed8c3a253c67d9c3cb23e0f497ad\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.0.1+cu118)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.10.1)\n",
            "Collecting accelerate (from -r requirements.txt (line 3))\n",
            "  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.4.4)\n",
            "Collecting loralib (from -r requirements.txt (line 5))\n",
            "  Downloading loralib-0.1.1-py3-none-any.whl (8.8 kB)\n",
            "Collecting bitsandbytes>=0.39.0 (from -r requirements.txt (line 6))\n",
            "  Downloading bitsandbytes-0.39.1-py3-none-any.whl (97.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.1/97.1 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black[jupyter] (from -r requirements.txt (line 7))\n",
            "  Downloading black-23.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from -r requirements.txt (line 8))\n",
            "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fire (from -r requirements.txt (line 9))\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (4.65.0)\n",
            "Collecting sentencepiece (from -r requirements.txt (line 11))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting text_generation (from -r requirements.txt (line 12))\n",
            "  Downloading text_generation-0.6.0-py3-none-any.whl (10 kB)\n",
            "Collecting guidance (from -r requirements.txt (line 13))\n",
            "  Downloading guidance-0.0.64-py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers (from -r requirements.txt (line 15))\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 1)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 1)) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->-r requirements.txt (line 2)) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 3)) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 3)) (6.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black[jupyter]->-r requirements.txt (line 7)) (8.1.3)\n",
            "Collecting mypy-extensions>=0.4.3 (from black[jupyter]->-r requirements.txt (line 7))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting pathspec>=0.9.0 (from black[jupyter]->-r requirements.txt (line 7))\n",
            "  Downloading pathspec-0.11.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black[jupyter]->-r requirements.txt (line 7)) (3.7.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black[jupyter]->-r requirements.txt (line 7)) (2.0.1)\n",
            "Requirement already satisfied: ipython>=7.8.0 in /usr/local/lib/python3.10/dist-packages (from black[jupyter]->-r requirements.txt (line 7)) (7.34.0)\n",
            "Collecting tokenize-rt>=3.2.0 (from black[jupyter]->-r requirements.txt (line 7))\n",
            "  Downloading tokenize_rt-5.1.0-py2.py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 8)) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets->-r requirements.txt (line 8))\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 8)) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 8)) (2.27.1)\n",
            "Collecting xxhash (from datasets->-r requirements.txt (line 8))\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->-r requirements.txt (line 8))\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 8)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 8)) (3.8.4)\n",
            "Collecting huggingface-hub<1.0.0,>=0.11.0 (from datasets->-r requirements.txt (line 8))\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->-r requirements.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->-r requirements.txt (line 9)) (2.3.0)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from text_generation->-r requirements.txt (line 12)) (1.10.9)\n",
            "Collecting diskcache (from guidance->-r requirements.txt (line 13))\n",
            "  Downloading diskcache-5.6.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gptcache (from guidance->-r requirements.txt (line 13))\n",
            "  Downloading gptcache-0.1.35-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai>=0.27.8 (from guidance->-r requirements.txt (line 13))\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from guidance->-r requirements.txt (line 13)) (3.1.0)\n",
            "Collecting pygtrie (from guidance->-r requirements.txt (line 13))\n",
            "  Downloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
            "Collecting tiktoken>=0.3 (from guidance->-r requirements.txt (line 13))\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from guidance->-r requirements.txt (line 13)) (1.5.6)\n",
            "Collecting msal (from guidance->-r requirements.txt (line 13))\n",
            "  Downloading msal-1.22.0-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from peft==0.4.0.dev0->-r requirements.txt (line 14))\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 15)) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->-r requirements.txt (line 15))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 8)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 8)) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 8)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 8)) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 8)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 8)) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black[jupyter]->-r requirements.txt (line 7)) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=7.8.0->black[jupyter]->-r requirements.txt (line 7))\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black[jupyter]->-r requirements.txt (line 7)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black[jupyter]->-r requirements.txt (line 7)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black[jupyter]->-r requirements.txt (line 7)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black[jupyter]->-r requirements.txt (line 7)) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black[jupyter]->-r requirements.txt (line 7)) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black[jupyter]->-r requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black[jupyter]->-r requirements.txt (line 7)) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black[jupyter]->-r requirements.txt (line 7)) (4.8.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 8)) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 8)) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 8)) (3.4)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from gptcache->guidance->-r requirements.txt (line 13)) (5.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.3)\n",
            "Collecting PyJWT[crypto]<3,>=1.0.0 (from msal->guidance->-r requirements.txt (line 13))\n",
            "  Downloading PyJWT-2.7.0-py3-none-any.whl (22 kB)\n",
            "Collecting cryptography<43,>=0.6 (from msal->guidance->-r requirements.txt (line 13))\n",
            "  Downloading cryptography-41.0.1-cp37-abi3-manylinux_2_28_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 8)) (2022.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<43,>=0.6->msal->guidance->-r requirements.txt (line 13)) (1.15.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.8.0->black[jupyter]->-r requirements.txt (line 7)) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.8.0->black[jupyter]->-r requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.8.0->black[jupyter]->-r requirements.txt (line 7)) (0.2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<43,>=0.6->msal->guidance->-r requirements.txt (line 13)) (2.21)\n",
            "Building wheels for collected packages: fire, peft\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116932 sha256=d0144fd6c4312bb26686ccdd95a234840c856110bdf58bbe93b39286e8652724\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.4.0.dev0-py3-none-any.whl size=62150 sha256=8f3ac65ab65be22fdc317adabf386af4f899ca50b5b3c71bbce5889d7b07a4ce\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k6xj67m4/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\n",
            "Successfully built fire peft\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, pygtrie, bitsandbytes, xxhash, tokenize-rt, PyJWT, pathspec, mypy-extensions, loralib, jedi, fire, diskcache, dill, tiktoken, multiprocess, huggingface-hub, gptcache, cryptography, black, transformers, text_generation, openai, msal, datasets, guidance, accelerate, peft\n",
            "Successfully installed PyJWT-2.7.0 accelerate-0.20.3 bitsandbytes-0.39.1 black-23.3.0 cryptography-41.0.1 datasets-2.13.1 dill-0.3.6 diskcache-5.6.1 fire-0.5.0 gptcache-0.1.35 guidance-0.0.64 huggingface-hub-0.16.4 jedi-0.18.2 loralib-0.1.1 msal-1.22.0 multiprocess-0.70.14 mypy-extensions-1.0.0 openai-0.27.8 pathspec-0.11.1 peft-0.4.0.dev0 pygtrie-2.5.0 safetensors-0.3.1 sentencepiece-0.1.99 text_generation-0.6.0 tiktoken-0.4.0 tokenize-rt-5.1.0 tokenizers-0.13.3 transformers-4.30.2 xxhash-3.2.0\n",
            "Collecting alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip (from -r cuda_quant_requirements.txt (line 1))\n",
            "  Cloning https://github.com/taprosoft/alpaca_lora_4bit (to revision winglian-setup_pip) to /tmp/pip-install-4l0a0qo_/alpaca-lora-4bit_e1ed73b45ebb4eeeba924142562cd952\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/taprosoft/alpaca_lora_4bit /tmp/pip-install-4l0a0qo_/alpaca-lora-4bit_e1ed73b45ebb4eeeba924142562cd952\n",
            "  Running command git checkout -b winglian-setup_pip --track origin/winglian-setup_pip\n",
            "  Switched to a new branch 'winglian-setup_pip'\n",
            "  Branch 'winglian-setup_pip' set up to track remote branch 'winglian-setup_pip' from 'origin'.\n",
            "  Resolved https://github.com/taprosoft/alpaca_lora_4bit to commit 03397b34e4a7a806c68280de1761ebb74bbed827\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting exllama_lib@ git+https://github.com/taprosoft/exllama.git (from -r cuda_quant_requirements.txt (line 2))\n",
            "  Cloning https://github.com/taprosoft/exllama.git to /tmp/pip-install-4l0a0qo_/exllama-lib_060494c027234d5083db1c11048d34f4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/taprosoft/exllama.git /tmp/pip-install-4l0a0qo_/exllama-lib_060494c027234d5083db1c11048d34f4\n",
            "  Resolved https://github.com/taprosoft/exllama.git to commit aed938dee32447c11f82f616887bf53cfd939789\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting peft@ git+https://github.com/huggingface/peft.git (from -r cuda_quant_requirements.txt (line 3))\n",
            "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-install-4l0a0qo_/peft_cc490b98a8f94c8db7b623ef32daf31b\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-install-4l0a0qo_/peft_cc490b98a8f94c8db7b623ef32daf31b\n",
            "  Resolved https://github.com/huggingface/peft.git to commit 06fd06a4d2e8ed8c3a253c67d9c3cb23e0f497ad\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting xformers (from -r cuda_quant_requirements.txt (line 4))\n",
            "  Downloading xformers-0.0.20-cp310-cp310-manylinux2014_x86_64.whl (109.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gptq_llama@ git+https://github.com/sterlind/GPTQ-for-LLaMa.git@lora_4bit (from alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1))\n",
            "  Cloning https://github.com/sterlind/GPTQ-for-LLaMa.git (to revision lora_4bit) to /tmp/pip-install-4l0a0qo_/gptq-llama_1d10dca35b064a2dba11768d15bd9a0c\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/sterlind/GPTQ-for-LLaMa.git /tmp/pip-install-4l0a0qo_/gptq-llama_1d10dca35b064a2dba11768d15bd9a0c\n",
            "  Running command git checkout -b lora_4bit --track origin/lora_4bit\n",
            "  Switched to a new branch 'lora_4bit'\n",
            "  Branch 'lora_4bit' set up to track remote branch 'lora_4bit' from 'origin'.\n",
            "  Resolved https://github.com/sterlind/GPTQ-for-LLaMa.git to commit 8bfa7a4a35e72ae853722dbfd2e4d88afc736536\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (2.0.1+cu118)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (0.20.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (2.13.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (0.1.99)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (0.3.1)\n",
            "Collecting einops (from alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1))\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama (from alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (23.2.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (4.30.2)\n",
            "Collecting wandb (from alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1))\n",
            "  Downloading wandb-0.15.5-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (23.1)\n",
            "Collecting ninja==1.11.1 (from exllama_lib@ git+https://github.com/taprosoft/exllama.git->-r cuda_quant_requirements.txt (line 2))\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft@ git+https://github.com/huggingface/peft.git->-r cuda_quant_requirements.txt (line 3)) (1.22.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft@ git+https://github.com/huggingface/peft.git->-r cuda_quant_requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft@ git+https://github.com/huggingface/peft.git->-r cuda_quant_requirements.txt (line 3)) (6.0)\n",
            "Collecting pyre-extensions==0.0.29 (from xformers->-r cuda_quant_requirements.txt (line 4))\n",
            "  Downloading pyre_extensions-0.0.29-py3-none-any.whl (12 kB)\n",
            "Collecting typing-inspect (from pyre-extensions==0.0.29->xformers->-r cuda_quant_requirements.txt (line 4))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyre-extensions==0.0.29->xformers->-r cuda_quant_requirements.txt (line 4)) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (16.0.6)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (0.16.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (0.13.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (8.1.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1))\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1))\n",
            "  Downloading sentry_sdk-1.27.1-py2.py3-none-any.whl (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.7/211.7 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1))\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1))\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (1.3.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1))\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (2022.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect->pyre-extensions==0.0.29->xformers->-r cuda_quant_requirements.txt (line 4)) (1.0.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->alpaca_lora_4bit@ git+https://github.com/taprosoft/alpaca_lora_4bit@winglian-setup_pip->-r cuda_quant_requirements.txt (line 1))\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: alpaca_lora_4bit, exllama_lib, gptq_llama, pathtools\n",
            "  Building wheel for alpaca_lora_4bit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alpaca_lora_4bit: filename=alpaca_lora_4bit-0.1.2-py3-none-any.whl size=33997 sha256=b9610f77dac51919904448f636fdcab3d83021fad993acde0a30dd9672dcc7dd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-shziq1ut/wheels/7e/dc/3a/d90636d571409ed58cf866d6de4548f923a80b94ccb6785a98\n",
            "  Building wheel for exllama_lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for exllama_lib: filename=exllama_lib-0.1.0-py3-none-any.whl size=75206 sha256=cf9374405b5f7e809e843832ea911740535120d758078a16bcbfe4f4f846d04d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-shziq1ut/wheels/30/bc/de/180344b5e5b3e159c5cd564c8308f7becaa4a51e28110e0a45\n",
            "  Building wheel for gptq_llama (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gptq_llama: filename=gptq_llama-0.2.3-cp310-cp310-linux_x86_64.whl size=3668639 sha256=dc122acf1018c026c7bee1eb870bae5ef8ff529d739cc12551214c138af7e0f0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-shziq1ut/wheels/e4/bf/f8/8246ff9983862e99d4f813ef38ce647249d44c68f4b4f506f3\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=867dece443c238a7eeb597223de76c26e8da8a5991236f781320f78b88a31de4\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built alpaca_lora_4bit exllama_lib gptq_llama pathtools\n",
            "Installing collected packages: pathtools, ninja, typing-inspect, smmap, setproctitle, sentry-sdk, einops, docker-pycreds, colorama, pyre-extensions, gitdb, GitPython, wandb, gptq_llama, xformers, exllama_lib, alpaca_lora_4bit\n",
            "Successfully installed GitPython-3.1.31 alpaca_lora_4bit-0.1.2 colorama-0.4.6 docker-pycreds-0.4.0 einops-0.6.1 exllama_lib-0.1.0 gitdb-4.0.10 gptq_llama-0.2.3 ninja-1.11.1 pathtools-0.1.2 pyre-extensions-0.0.29 sentry-sdk-1.27.1 setproctitle-1.3.2 smmap-5.0.0 typing-inspect-0.9.0 wandb-0.15.5 xformers-0.0.20\n",
            "W&B disabled.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/taprosoft/llm_finetuning/\n",
        "%cd llm_finetuning\n",
        "!pip install -r requirements.txt\n",
        "!pip install -r cuda_quant_requirements.txt\n",
        "!wandb disabled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsXtmFArI3-9"
      },
      "source": [
        "Download some model weights from HuggingFace [model hub](https://huggingface.co/models) using the `download_model.py` script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2NsuwcFrZ4F",
        "outputId": "37a9c5c0-dd1f-4557-87ea-7cabe08c4613"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading the model to models/TheBloke_open-llama-7b-open-instruct-GPTQ\n",
            "100% 9.80k/9.80k [00:00<00:00, 37.1MiB/s]\n",
            "100% 576/576 [00:00<00:00, 3.43MiB/s]\n",
            "100% 132/132 [00:00<00:00, 935kiB/s]\n",
            "100% 3.90G/3.90G [03:33<00:00, 18.3MiB/s]\n",
            "100% 185/185 [00:00<00:00, 1.55MiB/s]\n",
            "100% 435/435 [00:00<00:00, 3.35MiB/s]\n",
            "100% 1.98M/1.98M [00:01<00:00, 1.89MiB/s]\n",
            "100% 534k/534k [00:00<00:00, 71.7MiB/s]\n",
            "100% 727/727 [00:00<00:00, 4.63MiB/s]\n",
            "Downloading the model to models/Epimachok_vicuna-7b-v1.3-sharded-bf16\n",
            "100% 552/552 [00:00<00:00, 3.70MiB/s]\n",
            "100% 137/137 [00:00<00:00, 1.05MiB/s]\n",
            "100% 1.98G/1.98G [00:22<00:00, 86.7MiB/s]\n",
            "100% 1.99G/1.99G [00:24<00:00, 81.0MiB/s]\n",
            " 29% 568M/1.99G [01:15<01:21, 17.4MiB/s]"
          ]
        }
      ],
      "source": [
        "!mkdir models\n",
        "# download a 7B GPTQ base model\n",
        "!python download_model.py TheBloke/open-llama-7b-open-instruct-GPTQ\n",
        "# download a normal 7B model (note that we have to use sharded checkpoint due to memory limit of Colab)\n",
        "!python download_model.py CleverShovel/vicuna-7b-v1.3-sharded-bf16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leNY_lU8Ji-m"
      },
      "source": [
        "Use `finetune.py` script to run training / inference. We first perform evaluation of the downloaded models on a public instruction-tuning datasets.\n",
        "\n",
        "To understand the format of the dataset, take a look at [alpaca-cleaned](https://huggingface.co/datasets/yahma/alpaca-cleaned) or the guideline in [README](https://github.com/taprosoft/llm_finetuning).\n",
        "\n",
        "It looks something likes this:\n",
        "\n",
        "```json\n",
        "[\n",
        "    {\n",
        "        \"instruction\": \"do something with the input\",\n",
        "        \"input\": \"input string\",\n",
        "        \"output\": \"output string\"\n",
        "    }\n",
        "]\n",
        "```\n",
        "\n",
        "We start with the 7B model on 4-bit quantization mode from `bitsandbytes`. Take a look at the output loss and processing time per step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFSrStbSASst"
      },
      "outputs": [],
      "source": [
        "!python finetune.py \\\n",
        "    --base_model 'models/CleverShovel_vicuna-7b-v1.3-sharded-bf16' \\\n",
        "    --data_path 'yahma/alpaca-cleaned' \\\n",
        "    --output_dir 'output_lora' \\\n",
        "    --batch_size 32 \\\n",
        "    --micro_batch_size 1 \\\n",
        "    --train_on_inputs True \\\n",
        "    --num_epochs 1 \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --cutoff_len 1600 \\\n",
        "    --group_by_length \\\n",
        "    --val_set_size 0.05 \\\n",
        "    --eval_steps 0 \\\n",
        "    --logging_steps 5 \\\n",
        "    --save_steps 5 \\\n",
        "    --gradient_checkpointing 1 \\\n",
        "    --mode 4 \\\n",
        "    --eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU61FgkgLqze"
      },
      "source": [
        "Now we will run the same script with GPTQ quantization mode (`--mode gptq`). Note that we need to switch to a compatible model weight to be used with this method. (look for `gptq` in the model name). We can see some significant difference in processing time using different quantization methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdy5ey7QnS0L"
      },
      "outputs": [],
      "source": [
        "!python finetune.py \\\n",
        "    --base_model 'models/TheBloke_open-llama-7b-open-instruct-GPTQ' \\\n",
        "    --data_path 'yahma/alpaca-cleaned' \\\n",
        "    --output_dir 'output_lora' \\\n",
        "    --batch_size 32 \\\n",
        "    --micro_batch_size 1 \\\n",
        "    --train_on_inputs True \\\n",
        "    --num_epochs 1 \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --cutoff_len 1600 \\\n",
        "    --group_by_length \\\n",
        "    --val_set_size 0.05 \\\n",
        "    --eval_steps 0 \\\n",
        "    --logging_steps 5 \\\n",
        "    --save_steps 5 \\\n",
        "    --gradient_checkpointing 1 \\\n",
        "    --mode gptq \\\n",
        "    --eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluation loop only provides the loss and run time measurement. To actually see the model output in text format, use `inference.py` script. Note that perform inference / generation will take much longer time than evaluation loop due to the additional overhead in token generation steps. We will use `exllama` inference backend to speed up the inference time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to fix some Colab install issue with Exllama\n",
        "!git clone https://github.com/taprosoft/exllama.git\n",
        "!cd exllama && pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python inference.py \\\n",
        "    --base models/TheBloke_open-llama-7b-open-instruct-GPTQ \\\n",
        "    --mode exllama \\\n",
        "    --data 'yahma/alpaca-cleaned' \\\n",
        "    --selected_ids [0,1,2,3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSgvc9ZxL6wy"
      },
      "source": [
        "Now we can start training. On a relatively old GPU like T4, it can take about 20-30h to complete the training on Alpaca dataset. Output checkpoint is stored in `output_lora`. Checkpoint is created at regular interval so you can stop earlier if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6J17VYR1MHav"
      },
      "outputs": [],
      "source": [
        "!python finetune.py \\\n",
        "    --base_model 'models/TheBloke_open-llama-7b-open-instruct-GPTQ' \\\n",
        "    --data_path 'yahma/alpaca-cleaned' \\\n",
        "    --output_dir 'output_lora' \\\n",
        "    --batch_size 32 \\\n",
        "    --micro_batch_size 1 \\\n",
        "    --train_on_inputs True \\\n",
        "    --num_epochs 1 \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --cutoff_len 1600 \\\n",
        "    --group_by_length \\\n",
        "    --val_set_size 0.05 \\\n",
        "    --eval_steps 0 \\\n",
        "    --logging_steps 5 \\\n",
        "    --save_steps 5 \\\n",
        "    --gradient_checkpointing 1 \\\n",
        "    --mode gptq"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
